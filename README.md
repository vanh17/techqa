# Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading

This repository contains code for the paper [Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading](https://dl.acm.org/doi/10.1145/3404835.3463099) accepted as a short paper and for presentation at [SIGIR'21](https://sigir.org/sigir2021/accepted-papers/)

1. Source code to augument training data for [TechQA](https://aclanthology.org/2020.acl-main.117/) under folder [agumentation](https://github.com/vanh17/techqa/tree/master/agumentation)
2. Source code to augment training data for [PolicyQA](https://aclanthology.org/2020.findings-emnlp.66.pdf) under folder [agumentation](https://github.com/vanh17/techqa/tree/master/agumentation)
3. Clone of evaluation/training scripts from TechQA task organizers that we used for results included in our paper under [IBM_BERT](https://github.com/vanh17/techqa/tree/master/IBM_BERT)
4. Clone of evaluation/training scripts from [Transformers' Github repo](https://github.com/huggingface/transformers/tree/v3.0.2-docs) version 3.0.2 that we used for results on PolicyQA dataset included in our paper under [transformers-3.0.2]()

### Requirements
We do not have particular requirements for our augmentation code. To run training/evaluation scripts, please refer to [TechQA's Github repo](https://github.com/IBM/techqa/blob/master/README.md) and [Transformers's Github repo](https://github.com/huggingface/transformers/tree/v3.0.2-docs) for their detailed requirements.

### Installation
You can ```git clone``` the whole directory into your desired location by running this command:
```
git clone https://github.com/vanh17/techqa.git
```

### How to augment training data


#### TechQA


##### 1. Baselines


##### 2. Data Augmentation


##### 3. Data Augmentation + Original Model


#### PolicyQA


##### 1. Baselines


##### 2. Data Augmentation




